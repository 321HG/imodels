{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import time, sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# short decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# load in same data\n",
    "boston_data = pd.read_csv(\"../data/boston.csv\", index_col=0)\n",
    "y = boston_data.medv.values\n",
    "X = boston_data.drop(\"medv\", axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "\n",
    "# specify a decision tree with a maximum depth\n",
    "dt = DecisionTreeRegressor(max_depth=3)\n",
    "dt.fit(X, y)\n",
    "\n",
    "# calculat mse on the training data\n",
    "preds = dt.predict(X)\n",
    "print(f'train mse: {np.mean(np.square(preds-y)):0.2f}')\n",
    "\n",
    "plot_tree(dt)\n",
    "plt.savefig('tree.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integer linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../imodels/slim')\n",
    "from SLIM import SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 0\tmse:  2.09\tweights: [ 1  1 -1  0  0  0  0  0  0  0]\n",
      "lambda: 0.01\tmse:  2.09\tweights: [ 1  1 -1  0  0  0  0  0  0  0]\n",
      "lambda: 0.05\tmse:  1.02\tweights: [ 1  2 -1  0  0  0  0  0  0  0]\n",
      "lambda: 0.1\tmse:  1.02\tweights: [ 1  2 -1  0  0  0  0  0  0  0]\n",
      "lambda: 1\tmse:  3.08\tweights: [ 0  1 -1  0  0  0  0  0  0  0]\n",
      "lambda: 2\tmse:  1.90\tweights: [ 0  2 -1  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# generate X and y\n",
    "n, p = 1000, 10\n",
    "X = np.random.randn(n, p)\n",
    "y = X[:, 0] + 2 * X[:, 1] - 1 * X[:, 2] + np.random.randn(n)\n",
    "\n",
    "# fit linear models with different regularization parameters\n",
    "model = SLIM()\n",
    "for lambda_reg in [0, 1e-2, 5e-2, 1e-1, 1, 2]:\n",
    "    model.fit(X, y, lambda_reg)\n",
    "    mse = np.mean(np.square(y - model.predict(X)))\n",
    "    print(f'lambda: {lambda_reg}\\tmse: {mse: 0.2f}\\tweights: {model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rulefit\n",
    "- installed with: `pip install git+git://github.com/christophM/rulefit.git`\n",
    "- [documentation](https://github.com/christophM/rulefit) and the [original paper](http://statweb.stanford.edu/~jhf/ftp/RuleFit.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.97186577065486, tolerance: 4.2716295415019765\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from rulefit import RuleFit\n",
    "\n",
    "# load some data\n",
    "boston_data = pd.read_csv(\"../data/boston.csv\", index_col=0)\n",
    "y = boston_data.medv.values\n",
    "X = boston_data.drop(\"medv\", axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "\n",
    "# fit a rulefit model\n",
    "rf = RuleFit()\n",
    "rf.fit(X, y, feature_names=features)\n",
    "\n",
    "# calculate mse on the training data\n",
    "preds = rf.predict(X)\n",
    "print(f'train mse: {np.mean(np.square(preds-y)):0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's inspect the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow0_col1 {\n",
       "            background-color:  #3aba76;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow0_col2 {\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow1_col1 {\n",
       "            background-color:  #3fbc73;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow1_col2 {\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow2_col1 {\n",
       "            background-color:  #34b679;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow2_col2 {\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow3_col1 {\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow3_col2 {\n",
       "            background-color:  #2a788e;\n",
       "            color:  #000000;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow4_col1 {\n",
       "            background-color:  #440154;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow4_col2 {\n",
       "            background-color:  #440154;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0a\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rule</th>        <th class=\"col_heading level0 col1\" >coef</th>        <th class=\"col_heading level0 col2\" >support</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0alevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow0_col0\" class=\"data row0 col0\" >zn</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow0_col1\" class=\"data row0 col1\" >0.00720871</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow0_col2\" class=\"data row0 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0alevel0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow1_col0\" class=\"data row1 col0\" >rad</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow1_col1\" class=\"data row1 col1\" >0.0402382</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow1_col2\" class=\"data row1 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0alevel0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow2_col0\" class=\"data row2 col0\" >age</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow2_col1\" class=\"data row2 col1\" >-0.0377822</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow2_col2\" class=\"data row2 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0alevel0_row3\" class=\"row_heading level0 row3\" >1217</th>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow3_col0\" class=\"data row3 col0\" >rm <= 8.752500057220459 & indus <= 26.69499969482422</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow3_col1\" class=\"data row3 col1\" >0.90752</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow3_col2\" class=\"data row3 col2\" >0.987179</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0alevel0_row4\" class=\"row_heading level0 row4\" >1193</th>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow4_col0\" class=\"data row4 col0\" >dis > 1.1716500520706177 & rm <= 8.168499946594238 & rm <= 8.752500057220459</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow4_col1\" class=\"data row4 col1\" >-1.88072</td>\n",
       "                        <td id=\"T_a1abfa9e_a2ef_11e9_a8ab_002590e83e0arow4_col2\" class=\"data row4 col2\" >0.978632</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7febefe1a898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = rf.get_rules()\n",
    "\n",
    "rules = rules[rules.coef != 0].sort_values(\"support\", ascending=False)\n",
    "\n",
    "# 'rule' is how the feature is constructed\n",
    "# 'coef' is its weight in the final linear model\n",
    "# 'support' is how many points it applies to\n",
    "rules[['rule', 'coef', 'support']].head().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scalable bayesian rule lists\n",
    "- docs are [here](https://github.com/csinva/interpretability-workshop/tree/master/models/bayesian_rule_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../imodels/bayesian_rule_lists')\n",
    "sys.path.append('../imodels/bayesian_rule_lists/discretization')\n",
    "from RuleListClassifier import *\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "feature_labels = [\"#Pregnant\",\"Glucose concentration test\",\"Blood pressure(mmHg)\",\"Triceps skin fold thickness(mm)\",\n",
    "                  \"2-Hour serum insulin (mu U/ml)\",\"Body mass index\",\"Diabetes pedigree function\",\"Age (years)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "RuleListClassifier Accuracy: 0.7065972222222222 Learned interpretable model:\n",
      " Trained RuleListClassifier for detecting diabetes\n",
      "==================================================\n",
      "IF #Pregnant : 6.5_to_inf THEN probability of diabetes: 65.7% (49.5%-80.3%)\n",
      "ELSE IF Glucose concentration test : -inf_to_122.5 THEN probability of diabetes: 9.9% (4.9%-16.4%)\n",
      "ELSE IF Body mass index : -inf_to_30.9 THEN probability of diabetes: 36.0% (18.8%-55.3%)\n",
      "ELSE probability of diabetes: 69.2% (54.1%-82.5%)\n",
      "=================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "data = fetch_openml(\"diabetes\") # get dataset\n",
    "y = (data.target == 'tested_positive').astype(np.int) # labels 0-1\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data.data, y, test_size=0.75) # split\n",
    "\n",
    "# train classifier (allow more iterations for better accuracy; use BigDataRuleListClassifier for large datasets)\n",
    "print('training...')\n",
    "model = RuleListClassifier(max_iter=10000, class1label=\"diabetes\", verbose=False)\n",
    "model.fit(Xtrain, ytrain, feature_labels=feature_labels)\n",
    "\n",
    "print(\"RuleListClassifier Accuracy:\", model.score(Xtest, ytest), \"Learned interpretable model:\\n\", model)\n",
    "# print(\"RandomForestClassifier Accuracy:\", RandomForestClassifier(n_estimators=10).fit(Xtrain, ytrain).score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimal classification tree\n",
    "- docs [here](https://github.com/csinva/interpretability-workshop/tree/master/models/optimal_classification_tree)\n",
    "- note: this implementation is still somewhat unstable, and can be made faster by installing either `cplex` or `gurobi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../imodels/optimal_classification_tree/pyoptree')\n",
    "sys.path.append('../imodels/optimal_classification_tree/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optree import OptimalTreeModel\n",
    "feature_names = np.array([\"x1\", \"x2\"])\n",
    "\n",
    "X = np.array([[1, 2, 2, 2, 3], [1, 2, 1, 0, 1]]).T\n",
    "y = np.array([1, 1, 0, 0, 0]).reshape(-1, 1)\n",
    "X_test = np.array([[1, 1, 2, 2, 2, 3, 3], [1, 2, 2, 1, 0, 1, 0]]).T\n",
    "y_test = np.array([1, 1, 1, 0, 0, 0, 0])\n",
    "\n",
    "np.random.seed(13)\n",
    "model = OptimalTreeModel(tree_depth=3, N_min=1, alpha=0.1) #, solver_name='baron'\n",
    "model.fit(X_test, y_test) # this method is currently using the fast, but not optimal solver\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# fit on the bigger diabetes dset from above\n",
    "# model.fit(Xtrain, ytrain) # this method is currently using the fast, but not optimal solver\n",
    "# preds = model.predict(Xtest)\n",
    "\n",
    "print('acc', np.mean(preds == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0:\n",
      "\t x2 > 0.8114524236945737\n",
      "\n",
      "depth 1:\n",
      "\tnode 2 undefined\n",
      "\tnode 3 undefined\n",
      "\n",
      "depth 2:\n",
      "\tnode 4 undefined\n",
      "\t x1 > 0.01086684288089712\n",
      "\t x2 > 0.9159532769401844\n",
      "\tnode 7 undefined\n",
      "\n",
      "depth 3:\n",
      "\tnode 8 undefined\n",
      "\tnode 9 undefined\n",
      "\tnode 10 undefined\n",
      "\tnode 11 undefined\n",
      "\tnode 12 undefined\n",
      "\tnode 13 undefined\n",
      "\tnode 14 undefined\n",
      "\tnode 15 undefined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.print_tree(feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
